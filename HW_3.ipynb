{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Домашнее задание по теме урока: Логистическая регрессия. Log Loss.\n",
    "**Постараюсь реализовать многоклассовую логрегрессию (частный случай которой - 2 класса**)\n",
    "\n",
    "***Соответствующими комметариями буду указывать на реализации кода, которые соответствуют номерам ДЗ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
    "              [1, 1, 2, 5, 3, 0, 5, 10, 1, 2],\n",
    "              [500, 700, 750, 600, 1450, 800, 1500, 2000, 450, 1000],\n",
    "              [1, 1, 2, 1, 2,  1, 3, 3, 1, 2]], dtype = np.float64)\n",
    "y = np.array([0, 0, 1, 0, 1, 0, 1, 0, 1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_std_feat(x):\n",
    "    res = (x - x.mean()) / x.std()\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_st = X.copy()\n",
    "X_st[2, :] = calc_std_feat(X[2, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ],\n",
       "       [ 1.        ,  1.        ,  2.        ,  5.        ,  3.        ,\n",
       "         0.        ,  5.        , 10.        ,  1.        ,  2.        ],\n",
       "       [-0.97958969, -0.56713087, -0.46401617, -0.77336028,  0.97958969,\n",
       "        -0.36090146,  1.08270439,  2.11385144, -1.08270439,  0.05155735],\n",
       "       [ 1.        ,  1.        ,  2.        ,  1.        ,  2.        ,\n",
       "         1.        ,  3.        ,  3.        ,  1.        ,  2.        ]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''функция для преобразования вектора индексов классов в матрицу, содержащий\n",
    "one-hot веткор для каждого экземпляра. В нашем случае это два экземпляра,\n",
    "но данная реализация может быть использованап по множество экземпляров'''\n",
    "def to_one_hot(y):\n",
    "    n_classes = y.max() + 1\n",
    "    m = len(y)\n",
    "    Y_one_hot = np.zeros((m, n_classes))\n",
    "    Y_one_hot[np.arange(m), y] = 1\n",
    "    return Y_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 1, 0, 1, 0, 1, 1])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train_one_hot = to_one_hot(y)\n",
    "Y_train_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#реализация функции softmax (как в scipy.special) (оно же, по сути, №3 домашки)\n",
    "def softmax(logits):\n",
    "    exps = np.exp(logits)\n",
    "    exp_sums = np.sum(exps, axis=1, keepdims=True)\n",
    "    return exps / exp_sums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 2)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# определим количество входов и выходов для обучения\n",
    "n_inputs = X_st.T.shape[1] # == 4 (3 признака плюс смещение)\n",
    "n_outputs = len(np.unique(y))   # == 2 класса\n",
    "n_inputs, n_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Измените функцию calc_logloss так, чтобы нули по возможности не попадали в np.log."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*при реализации просто добавлю epsilon = 1e-7, это избавит как от нулей, так и от nan*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.8849594396399738\n",
      "500 0.5206043754780034\n",
      "1000 0.4673373707015725\n",
      "1500 0.4330359244906285\n",
      "2000 0.40640762491548726\n",
      "2500 0.3850671400483333\n",
      "3000 0.36772381015948136\n",
      "3500 0.3534427427482506\n",
      "4000 0.34152086495490275\n",
      "4500 0.3314307438324783\n",
      "5000 0.3227771741632863\n",
      "5500 0.3152628888808072\n",
      "6000 0.3086626429852748\n",
      "6500 0.3028041731654258\n",
      "7000 0.2975543842871299\n",
      "7500 0.2928093571827214\n",
      "8000 0.28848710125660815\n",
      "8500 0.28452226685361814\n",
      "9000 0.2808622575899294\n",
      "9500 0.27746434703806017\n",
      "10000 0.27429352062892814\n"
     ]
    }
   ],
   "source": [
    "eta = 0.01\n",
    "n_iterations = 10001\n",
    "m = len(X_st)\n",
    "epsilon = 1e-7\n",
    "\n",
    "Theta = np.random.randn(n_inputs, n_outputs)\n",
    "\n",
    "for iteration in range(n_iterations):\n",
    "    logits = X_st.T.dot(Theta)#транспонирую X_st (здесь везде далее), чтобы соответствовать стандартным формулам\n",
    "    Y_proba = softmax(logits)\n",
    "    loss = -np.mean(np.sum(Y_train_one_hot * np.log(Y_proba + epsilon), axis=1))\n",
    "    error = Y_proba - Y_train_one_hot\n",
    "    if iteration % 500 == 0:\n",
    "        print(iteration, loss)\n",
    "    gradients = 1/m * X_st.dot(error)\n",
    "    Theta = Theta - eta * gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.89369171, -3.65092657],\n",
       "       [ 1.60299608,  0.45776763],\n",
       "       [ 0.79637459, -0.61327012],\n",
       "       [-4.28314345,  2.33785836]])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.66551552, 0.33448448],\n",
       "        [0.78063863, 0.21936137],\n",
       "        [0.01693944, 0.98306056],\n",
       "        [0.99616443, 0.00383557],\n",
       "        [0.29300652, 0.70699348],\n",
       "        [0.6022559 , 0.3977441 ],\n",
       "        [0.00626796, 0.99373204],\n",
       "        [0.89222541, 0.10777459],\n",
       "        [0.63242085, 0.36757915],\n",
       "        [0.03441469, 0.96558531]]),\n",
       " array([0, 0, 1, 0, 1, 0, 1, 0, 0, 1], dtype=int64))"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ДЗ 3 и 4\n",
    "logits = X_st.T.dot(Theta)\n",
    "Y_proba = softmax(logits) # это есть номер 3 домашки\n",
    "y_predict = np.argmax(Y_proba, axis=1) # это есть номер 4 домашки\n",
    "Y_proba,y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ДЗ 5\n",
    "accuracy_score = np.mean(y_predict == y)\n",
    "accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>𝑦=+1</th>\n",
       "      <th>𝑦=−1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>𝑎(𝑥)=+1</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>𝑎(𝑥)=−1</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         𝑦=+1  𝑦=−1\n",
       "𝑎(𝑥)=+1     4     6\n",
       "𝑎(𝑥)=−1     5     5"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ДЗ 5\n",
    "table = np.array([sum(y_predict), len(y)-sum(y_predict), sum(y), len(y)-sum(y)]).reshape(2, 2)\n",
    "confusion_df = pd.DataFrame(table, ['𝑎(𝑥)=+1', '𝑎(𝑥)=−1'], ['𝑦=+1', '𝑦=−1'])\n",
    "confusion_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.4, 0.4444444444444444, 0.4210526315789474)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ДЗ 5\n",
    "Precission = confusion_df.iloc[0, 0]/(confusion_df.iloc[0, 0] + confusion_df.iloc[0, 1])\n",
    "Recall = confusion_df.iloc[0, 0]/(confusion_df.iloc[0, 0] + confusion_df.iloc[1, 0])\n",
    "F = (2*Precission*Recall)/(Precission+Recall)\n",
    "Precission, Recall, F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ДЗ 2 и 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Да модель могла переобучиться, потому что мы никак не ограничивали наши веса. Ниже я делаю реализацию регуляризации, а также прекращения градиентного спуска во избежание лишних иттераций (что соответствкет ДЗ 2 по сути)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.4808548146474751\n",
      "10 0.8368955129234252\n",
      "20 0.7367632859953441\n",
      "30 0.6994523807427235\n",
      "40 0.6707961729201005\n",
      "50 0.6471381032008142\n",
      "60 0.62753995374513\n",
      "70 0.6113386484563603\n",
      "80 0.5979939325731315\n",
      "90 0.587052865631403\n",
      "100 0.5781321980737022\n",
      "110 0.570906977541903\n",
      "120 0.5651018741444419\n",
      "130 0.5604839792822818\n",
      "140 0.5568566176827491\n",
      "150 0.5540539808210774\n",
      "160 0.55193647780917\n",
      "170 0.5503867264675005\n",
      "180 0.549306114896192\n",
      "190 0.5486118670116448\n",
      "200 0.5482345487763649\n",
      "210 0.5481159562038957\n",
      "210 0.5481159562038957\n",
      "211 0.5481163763633492 early stopping!\n"
     ]
    }
   ],
   "source": [
    "eta = 0.1 \n",
    "n_iterations = 10001\n",
    "m = len(X_st)\n",
    "epsilon = 1e-7\n",
    "alpha = 0.1  # гиперпараметр регуляризации\n",
    "best_loss = np.infty\n",
    "\n",
    "Theta = np.random.randn(n_inputs, n_outputs)\n",
    "\n",
    "for iteration in range(n_iterations):\n",
    "    logits = X_st.T.dot(Theta)\n",
    "    Y_proba = softmax(logits)\n",
    "    xentropy_loss = -np.mean(np.sum(Y_train_one_hot * np.log(Y_proba + epsilon), axis=1))\n",
    "    l2_loss = 1/2 * np.sum(np.square(Theta[1:]))\n",
    "    loss = xentropy_loss + alpha * l2_loss\n",
    "    error = Y_proba - Y_train_one_hot\n",
    "    gradients = 1/m * X_st.dot(error) + np.r_[np.zeros([1, n_outputs]), alpha * Theta[1:]]\n",
    "    Theta = Theta - eta * gradients\n",
    "\n",
    "    logits = X_st.T.dot(Theta)\n",
    "    Y_proba = softmax(logits)\n",
    "    xentropy_loss = -np.mean(np.sum(Y_train_one_hot * np.log(Y_proba + epsilon), axis=1))\n",
    "    l2_loss = 1/2 * np.sum(np.square(Theta[1:]))\n",
    "    loss = xentropy_loss + alpha * l2_loss\n",
    "    if iteration % 10 == 0:\n",
    "        print(iteration, loss)\n",
    "    if loss < best_loss:\n",
    "        best_loss = loss\n",
    "    else:\n",
    "        print(iteration - 1, best_loss)\n",
    "        print(iteration, loss, \"early stopping!\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.69946563, -0.8870627 ],\n",
       "       [ 0.34867677, -0.30854701],\n",
       "       [-0.08761391,  0.25104296],\n",
       "       [-0.87694978,  1.19983414]])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.62215683, 0.37784317],\n",
       "        [0.58880584, 0.41119416],\n",
       "        [0.25059346, 0.74940654],\n",
       "        [0.95511667, 0.04488333],\n",
       "        [0.2835108 , 0.7164892 ],\n",
       "        [0.4090162 , 0.5909838 ],\n",
       "        [0.15130916, 0.84869084],\n",
       "        [0.77074878, 0.22925122],\n",
       "        [0.63033017, 0.36966983],\n",
       "        [0.21924832, 0.78075168]]),\n",
       " array([0, 0, 1, 0, 1, 1, 1, 0, 0, 1], dtype=int64))"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = X_st.T.dot(Theta)\n",
    "Y_proba = softmax(logits) # это есть номер 3 домашки\n",
    "y_predict = np.argmax(Y_proba, axis=1) # это есть номер 4 домашки\n",
    "Y_proba,y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score = np.mean(y_predict == y)\n",
    "accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>𝑦=+1</th>\n",
       "      <th>𝑦=−1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>𝑎(𝑥)=+1</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>𝑎(𝑥)=−1</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         𝑦=+1  𝑦=−1\n",
       "𝑎(𝑥)=+1     5     5\n",
       "𝑎(𝑥)=−1     5     5"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table = np.array([sum(y_predict), len(y)-sum(y_predict), sum(y), len(y)-sum(y)]).reshape(2, 2)\n",
    "confusion_df = pd.DataFrame(table, ['𝑎(𝑥)=+1', '𝑎(𝑥)=−1'], ['𝑦=+1', '𝑦=−1'])\n",
    "confusion_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5, 0.5, 0.5)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Precission = confusion_df.iloc[0, 0]/(confusion_df.iloc[0, 0] + confusion_df.iloc[0, 1])\n",
    "Recall = confusion_df.iloc[0, 0]/(confusion_df.iloc[0, 0] + confusion_df.iloc[1, 0])\n",
    "F = (2*Precission*Recall)/(Precission+Recall)\n",
    "Precission, Recall, F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вот видим ,что веса меньше, а Precission и Recall при относительном равенстве accuracy лучше** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
